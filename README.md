# Augment-Vision-Drone

## Description
![image](https://github.com/rishikesh2715/Augment-Vision-Drone/assets/72249404/dcc06c8b-52a7-43ae-9d82-a8fef891ab46)
The **Augment-Vision-Drone** is a groundbreaking project that introduces a foldable drone equipped with auto-deployment and augmented reality (AR) capabilities. This drone can detect objects of interest and overlay their information onto a VR headset, pinpointing their exact direction and distance, even if these objects aren't in the user's direct line of sight.

## Project Outline
https://github.com/rishikesh2715/Augment-Vision-Drone/assets/72249404/c8a2ea8d-f2c1-446d-b462-615fb7fdb45f
### 1. Auto Deployment
We are in the process of designing a 3D body with spring-loaded foldable arms that can auto-deploy when the drone is thrown into the air. Currently, we are testing our third iteration of the drone body. The initial two iterations have proven that our control algorithm can stabilize the drone regardless of its orientation when thrown. We are optimistic that this iteration of the drone frame will be successful. This phase of the project is ongoing.

### 2. Object Detection Model
https://github.com/rishikesh2715/Augment-Vision-Drone/assets/72249404/e26e6b2b-a58c-4abd-882a-1e7397c7bb89

This phase involved developing an object detection model that operates seamlessly on the drone. We are pleased to announce that this part of the project has been completed successfully.

### 3. AR Overlay on VR Headset
The objective of this phase is to overlay the detected object's distance and direction onto a VR headset, ensuring it aligns with a team member's line of sight. This part of the project is still in progress.

## Contributing
If you're passionate about drones, AR, and the future of aerial technology, we'd love to have you on board! If you're interested in being a part of this project and potentially joining a startup in the future, please contact us. We are actively seeking motivated individuals to contribute to this innovative venture.

## Contact

For any questions or collaboration opportunities, please contact us at rishikesh3304@gmail.com or stephen.gillet@gmail.com


